{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mfcc_bee.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bee buzz MFCC model training and export to tflite\n",
        "\n",
        "Download the data - after extracting features through a processing block - so we can train a machine learning model."
      ],
      "metadata": {
        "id": "pBD5OA5mSLX6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIst1l9dR4EI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "API_KEY = 'ei_bf5f821cc24a036eb3f388396a4ce0e0aa8e16fba6198c90f585e72f3b820c79'\n",
        "\n",
        "def download_data(url):\n",
        "    response = requests.get(url, headers={'x-api-key': API_KEY})\n",
        "    if response.status_code == 200:\n",
        "        return response.content\n",
        "    else:\n",
        "        print(response.content)\n",
        "        raise ConnectionError('Could not download data file')\n",
        "\n",
        "X = download_data('https://studio.edgeimpulse.com/v1/api/94516/training/56/x')\n",
        "Y = download_data('https://studio.edgeimpulse.com/v1/api/94516/training/56/y')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store the data in a temporary file, and load it back through Numpy.\n"
      ],
      "metadata": {
        "id": "gBRVzwXMSPJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('x_train.npy', 'wb') as file:\n",
        "    file.write(X)\n",
        "with open('y_train.npy', 'wb') as file:\n",
        "    file.write(Y)\n",
        "X = np.load('x_train.npy')\n",
        "Y = np.load('y_train.npy')[:,0]"
      ],
      "metadata": {
        "id": "-_mWlyzOSI9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define our labels and split the data up in a test and training set:\n"
      ],
      "metadata": {
        "id": "fbODGLecSTz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os, random\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "# Set random seeds for repeatable results\n",
        "RANDOM_SEED = 3\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "classes_values = [ \"Bee\", \"notBee\" ]\n",
        "classes = len(classes_values)\n",
        "\n",
        "Y = tf.keras.utils.to_categorical(Y - 1, classes)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "\n",
        "input_length = X_train[0].shape[0]\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
        "\n",
        "def get_reshape_function(reshape_to):\n",
        "    def reshape(image, label):\n",
        "        return tf.reshape(image, reshape_to), label\n",
        "    return reshape\n",
        "\n",
        "callbacks = []"
      ],
      "metadata": {
        "id": "wPIv1nScSVQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model:\n"
      ],
      "metadata": {
        "id": "6Kmo_xW_SYeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer, Dropout, Conv1D, Conv2D, Flatten, Reshape, MaxPooling1D, MaxPooling2D, BatchNormalization, TimeDistributed\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# model architecture\n",
        "model = Sequential()\n",
        "model.add(Reshape((int(input_length / 13), 13), input_shape=(input_length, )))\n",
        "model.add(Conv1D(16, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
        "model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(classes, activation='softmax', name='y_pred'))\n",
        "\n",
        "# this controls the learning rate\n",
        "opt = Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999)\n",
        "# this controls the batch size, or you can manipulate the tf.data.Dataset objects yourself\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
        "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
        "\n",
        "# train the neural network\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model.fit(train_dataset, epochs=100, validation_data=validation_dataset, verbose=2, callbacks=callbacks)\n",
        "\n",
        "# Use this flag to disable per-channel quantization for a model.\n",
        "# This can reduce RAM usage for convolutional models, but may have\n",
        "# an impact on accuracy.\n",
        "disable_per_channel_quantization = False"
      ],
      "metadata": {
        "id": "VXgSpyINSanj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert model to tflite"
      ],
      "metadata": {
        "id": "MBrcob6jVvBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "tflite_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxM61tPDVKcX",
        "outputId": "ed0f4e66-8a6b-4ea8-f819-75686672cd97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate a representative dataset"
      ],
      "metadata": {
        "id": "XxlIDHC9V0Hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def representative_data_gen():\n",
        "  for input_value in tf.data.Dataset.from_tensor_slices(X_train).batch(1).take(100):\n",
        "    yield [input_value]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "# Ensure that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "\n",
        "tflite_model_quant = converter.convert()"
      ],
      "metadata": {
        "id": "NCf2TAVHVzeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0837cc4d-4d67-40a6-caae-eb28a0ed1291"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save int8 quantized model"
      ],
      "metadata": {
        "id": "OXYiql_EXcyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"/content/mfcc_bee2.0_model/\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir/\"bee2.0_model_quant.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_model_quant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qXcjA8UXi13",
        "outputId": "0e6aa259-0c5e-4cb4-a2d1-6bb898bb1a9b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11096"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verification test"
      ],
      "metadata": {
        "id": "o0_yoWoBYP4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=\"/content/mfcc_bee2.0_model/bee2.0_model_quant.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "\n",
        "# Test the model on random input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "print(\"Input format expected by model:\", input_shape)\n",
        "\n",
        "# generate random sample\n",
        "input_data = np.array(np.random.random_sample(input_shape), dtype=np.uint8)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "interpreter.invoke()\n",
        "\n",
        "# The function `get_tensor()` returns a copy of the tensor data.\n",
        "# Use `tensor()` in order to get a pointer to the tensor.\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Result:\",output_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WoORF4kYROa",
        "outputId": "981a5cd2-6d44-4928-a658-f234d1e99ba1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input format expected by model: [  1 806]\n",
            "Result: [  0 255]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To convert bee2.0_model_quant.tflite to C array use unix command: \n",
        "\n",
        "```\n",
        "xxd -i bee2.0_model_quant.tflite > bee2.0_model_quant.cc\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "aZQiDaZRYwU2"
      }
    }
  ]
}